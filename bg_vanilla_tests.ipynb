{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "    RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from scipy.stats import uniform\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df filt shape:  (7657, 10790)\n",
      "num_x_cols: 10777\n",
      "(7657, 10776)\n",
      "(7657,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('./all_data.pkl')\n",
    "\n",
    "NUM_LABEL_COLS = 13\n",
    "NUM_COMPONENTS = 26\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "#####################################\n",
    "#####################################\n",
    "\n",
    "df_filtered = df\n",
    "df_filtered.shape\n",
    "\n",
    "# exclude records we want to exclude\n",
    "df_filtered = df_filtered[df_filtered['trmp'] == '0']\n",
    "df_filtered = df_filtered[df_filtered['trmb'] == '0']\n",
    "df_filtered = df_filtered[df_filtered['otrb'] == '0']\n",
    "df_filtered = df_filtered[df_filtered['ext'] == '0']\n",
    "df_filtered = df_filtered[df_filtered['excl'] == '0']\n",
    "print('df filt shape: ', df_filtered.shape)\n",
    "\n",
    "# we are keeping sop, alt, tenr, tora, bari, clrt, other = 7\n",
    "                                                                        # off by one?\n",
    "num_x_cols = df_filtered.shape[1] - NUM_LABEL_COLS                      # - 1 \n",
    "print('num_x_cols:', num_x_cols)\n",
    "\n",
    "data = df_filtered.iloc[:, 1:num_x_cols].to_numpy() \n",
    "# ^ These are the features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "\n",
    "# Create target column\n",
    "combined = df_filtered[['sop']].to_numpy() + \\\n",
    "    df_filtered[['alto']].to_numpy() + \\\n",
    "    df_filtered[['tenr']].to_numpy() + \\\n",
    "    df_filtered[['tora']].to_numpy() + \\\n",
    "    df_filtered[['bari']].to_numpy()\n",
    "    \n",
    "combined = combined.astype('int')\n",
    "combined[combined > 0] = 1\n",
    "df_filtered['sax'] = combined\n",
    "\n",
    "target = df_filtered[['sax']].to_numpy().ravel()  # << This is the label\n",
    "\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "\n",
    "#####################################\n",
    "#####################################\n",
    "\n",
    "pca = PCA(n_components=NUM_COMPONENTS)\n",
    "pca.fit(data)\n",
    "PCA(n_components=29)\n",
    "\n",
    "d = pca.transform(data)\n",
    "\n",
    "#####################################\n",
    "#####################################\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "     train_test_split(d, target, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifer(clf, x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    # train model\n",
    "    clf_trained = clf.fit(x_train,y_train)\n",
    "\n",
    "#     print(x_train.shape)\n",
    "#     print(x_test.shape)\n",
    "#     print(y_train.shape)\n",
    "#     print(y_test.shape)\n",
    "    \n",
    "    # test model\n",
    "    y_predict = clf.predict(x_test)\n",
    "    # score model\n",
    "    clf_score = clf.score(x_test, y_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_predict))\n",
    "    \n",
    "    confus_mat = pd.DataFrame(confusion_matrix(y_test, y_predict))\n",
    "    \n",
    "    c_matrix = confusion_matrix(y_test, y_predict)\n",
    "    idx = cols = [0, 1]\n",
    "    cf_mat_pd = pd.DataFrame(c_matrix, index=idx, columns=cols)\n",
    "    print(cf_mat_pd)\n",
    "#     plt.imshow(confus_mat)\n",
    "    \n",
    "    return {'clf_trained': clf_trained,\\\n",
    "            'x_train': x_train, 'x_test': x_test,\\\n",
    "            'y_train': y_train, 'y_test': y_test,\\\n",
    "            'y_predict': y_predict,\\\n",
    "            'clf_score':clf_score,\\\n",
    "            'confus_mat':confus_mat}\n",
    "    \n",
    "def show_confus(eval_clf):\n",
    "    plt.imshow(eval_clf['confus_mat'])\n",
    "    plt.xlabel('predicted class')\n",
    "    plt.ylabel('actual class')\n",
    "    plt.title('confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.70       614\n",
      "           1       0.78      0.92      0.84       918\n",
      "\n",
      "    accuracy                           0.79      1532\n",
      "   macro avg       0.80      0.76      0.77      1532\n",
      "weighted avg       0.80      0.79      0.78      1532\n",
      "\n",
      "     0    1\n",
      "0  369  245\n",
      "1   74  844\n"
     ]
    }
   ],
   "source": [
    "clf_SVM_poly = SVC(kernel = 'poly')\n",
    "eval_SVM_poly = evaluate_classifer(clf_SVM_poly, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81       614\n",
      "           1       0.86      0.90      0.88       918\n",
      "\n",
      "    accuracy                           0.85      1532\n",
      "   macro avg       0.85      0.84      0.85      1532\n",
      "weighted avg       0.85      0.85      0.85      1532\n",
      "\n",
      "     0    1\n",
      "0  481  133\n",
      "1   90  828\n"
     ]
    }
   ],
   "source": [
    "clf_SVM_rbf = SVC(kernel='rbf')\n",
    "eval_SVM_rbf = evaluate_classifer(clf_SVM_rbf, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68       614\n",
      "           1       0.77      0.84      0.80       918\n",
      "\n",
      "    accuracy                           0.76      1532\n",
      "   macro avg       0.75      0.74      0.74      1532\n",
      "weighted avg       0.75      0.76      0.75      1532\n",
      "\n",
      "     0    1\n",
      "0  390  224\n",
      "1  151  767\n"
     ]
    }
   ],
   "source": [
    "clf_SVM_linear = SVC(kernel='linear')\n",
    "eval_SVM_linear = evaluate_classifer(clf_SVM_linear, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       614\n",
      "           1       0.83      0.82      0.82       918\n",
      "\n",
      "    accuracy                           0.79      1532\n",
      "   macro avg       0.78      0.79      0.78      1532\n",
      "weighted avg       0.79      0.79      0.79      1532\n",
      "\n",
      "     0    1\n",
      "0  463  151\n",
      "1  168  750\n"
     ]
    }
   ],
   "source": [
    "clf_forest_n10 = RandomForestClassifier(n_estimators=10)\n",
    "eval_forest_n10 = evaluate_classifer(clf_forest_n10, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49,)\n",
      "(49, 2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       614\n",
      "           1       0.76      0.76      0.76       918\n",
      "\n",
      "    accuracy                           0.71      1532\n",
      "   macro avg       0.70      0.70      0.70      1532\n",
      "weighted avg       0.71      0.71      0.71      1532\n",
      "\n",
      "     0    1\n",
      "0  391  223\n",
      "1  223  695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.84      0.68       614\n",
      "           1       0.84      0.57      0.68       918\n",
      "\n",
      "    accuracy                           0.68      1532\n",
      "   macro avg       0.70      0.70      0.68      1532\n",
      "weighted avg       0.73      0.68      0.68      1532\n",
      "\n",
      "     0    1\n",
      "0  513  101\n",
      "1  392  526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       614\n",
      "           1       0.77      0.78      0.78       918\n",
      "\n",
      "    accuracy                           0.73      1532\n",
      "   macro avg       0.72      0.72      0.72      1532\n",
      "weighted avg       0.73      0.73      0.73      1532\n",
      "\n",
      "     0    1\n",
      "0  398  216\n",
      "1  199  719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.69       614\n",
      "           1       0.83      0.67      0.74       918\n",
      "\n",
      "    accuracy                           0.72      1532\n",
      "   macro avg       0.72      0.73      0.72      1532\n",
      "weighted avg       0.74      0.72      0.72      1532\n",
      "\n",
      "     0    1\n",
      "0  486  128\n",
      "1  303  615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68       614\n",
      "           1       0.78      0.82      0.80       918\n",
      "\n",
      "    accuracy                           0.75      1532\n",
      "   macro avg       0.74      0.74      0.74      1532\n",
      "weighted avg       0.75      0.75      0.75      1532\n",
      "\n",
      "     0    1\n",
      "0  402  212\n",
      "1  167  751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.78      0.72       614\n",
      "           1       0.83      0.74      0.78       918\n",
      "\n",
      "    accuracy                           0.76      1532\n",
      "   macro avg       0.75      0.76      0.75      1532\n",
      "weighted avg       0.77      0.76      0.76      1532\n",
      "\n",
      "     0    1\n",
      "0  476  138\n",
      "1  236  682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.71       614\n",
      "           1       0.79      0.86      0.82       918\n",
      "\n",
      "    accuracy                           0.78      1532\n",
      "   macro avg       0.77      0.76      0.76      1532\n",
      "weighted avg       0.78      0.78      0.78      1532\n",
      "\n",
      "     0    1\n",
      "0  407  207\n",
      "1  133  785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       614\n",
      "           1       0.82      0.79      0.81       918\n",
      "\n",
      "    accuracy                           0.77      1532\n",
      "   macro avg       0.76      0.76      0.76      1532\n",
      "weighted avg       0.77      0.77      0.77      1532\n",
      "\n",
      "     0    1\n",
      "0  453  161\n",
      "1  191  727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73       614\n",
      "           1       0.80      0.86      0.83       918\n",
      "\n",
      "    accuracy                           0.79      1532\n",
      "   macro avg       0.79      0.78      0.78      1532\n",
      "weighted avg       0.79      0.79      0.79      1532\n",
      "\n",
      "     0    1\n",
      "0  422  192\n",
      "1  126  792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       614\n",
      "           1       0.84      0.80      0.82       918\n",
      "\n",
      "    accuracy                           0.79      1532\n",
      "   macro avg       0.78      0.78      0.78      1532\n",
      "weighted avg       0.79      0.79      0.79      1532\n",
      "\n",
      "     0    1\n",
      "0  471  143\n",
      "1  182  736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72       614\n",
      "           1       0.81      0.85      0.83       918\n",
      "\n",
      "    accuracy                           0.79      1532\n",
      "   macro avg       0.78      0.77      0.78      1532\n",
      "weighted avg       0.79      0.79      0.79      1532\n",
      "\n",
      "     0    1\n",
      "0  425  189\n",
      "1  137  781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       614\n",
      "           1       0.82      0.82      0.82       918\n",
      "\n",
      "    accuracy                           0.78      1532\n",
      "   macro avg       0.77      0.77      0.77      1532\n",
      "weighted avg       0.78      0.78      0.78      1532\n",
      "\n",
      "     0    1\n",
      "0  446  168\n",
      "1  167  751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73       614\n",
      "           1       0.81      0.86      0.83       918\n",
      "\n",
      "    accuracy                           0.79      1532\n",
      "   macro avg       0.79      0.78      0.78      1532\n",
      "weighted avg       0.79      0.79      0.79      1532\n",
      "\n",
      "     0    1\n",
      "0  426  188\n",
      "1  127  791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74       614\n",
      "           1       0.82      0.83      0.83       918\n",
      "\n",
      "    accuracy                           0.79      1532\n",
      "   macro avg       0.78      0.78      0.78      1532\n",
      "weighted avg       0.79      0.79      0.79      1532\n",
      "\n",
      "     0    1\n",
      "0  450  164\n",
      "1  157  761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.73       614\n",
      "           1       0.81      0.87      0.84       918\n",
      "\n",
      "    accuracy                           0.80      1532\n",
      "   macro avg       0.79      0.78      0.79      1532\n",
      "weighted avg       0.80      0.80      0.80      1532\n",
      "\n",
      "     0    1\n",
      "0  427  187\n",
      "1  121  797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75       614\n",
      "           1       0.83      0.84      0.84       918\n",
      "\n",
      "    accuracy                           0.80      1532\n",
      "   macro avg       0.80      0.79      0.79      1532\n",
      "weighted avg       0.80      0.80      0.80      1532\n",
      "\n",
      "     0    1\n",
      "0  459  155\n",
      "1  146  772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.73       614\n",
      "           1       0.81      0.87      0.84       918\n",
      "\n",
      "    accuracy                           0.80      1532\n",
      "   macro avg       0.80      0.78      0.79      1532\n",
      "weighted avg       0.80      0.80      0.80      1532\n",
      "\n",
      "     0    1\n",
      "0  422  192\n",
      "1  115  803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       614\n",
      "           1       0.83      0.85      0.84       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.80      0.80      0.80      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  453  161\n",
      "1  134  784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73       614\n",
      "           1       0.81      0.87      0.84       918\n",
      "\n",
      "    accuracy                           0.80      1532\n",
      "   macro avg       0.80      0.78      0.79      1532\n",
      "weighted avg       0.80      0.80      0.80      1532\n",
      "\n",
      "     0    1\n",
      "0  422  192\n",
      "1  116  802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       614\n",
      "           1       0.84      0.85      0.85       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.81      0.81      0.81      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  466  148\n",
      "1  136  782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75       614\n",
      "           1       0.82      0.87      0.85       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.81      0.80      0.80      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  441  173\n",
      "1  117  801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       614\n",
      "           1       0.82      0.85      0.84       918\n",
      "\n",
      "    accuracy                           0.80      1532\n",
      "   macro avg       0.79      0.79      0.79      1532\n",
      "weighted avg       0.80      0.80      0.80      1532\n",
      "\n",
      "     0    1\n",
      "0  446  168\n",
      "1  136  782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       614\n",
      "           1       0.80      0.89      0.84       918\n",
      "\n",
      "    accuracy                           0.80      1532\n",
      "   macro avg       0.80      0.78      0.79      1532\n",
      "weighted avg       0.80      0.80      0.80      1532\n",
      "\n",
      "     0    1\n",
      "0  411  203\n",
      "1  103  815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       614\n",
      "           1       0.83      0.86      0.84       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.80      0.79      0.80      1532\n",
      "weighted avg       0.80      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  449  165\n",
      "1  132  786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76       614\n",
      "           1       0.83      0.88      0.85       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.81      0.80      0.80      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  444  170\n",
      "1  114  804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       614\n",
      "           1       0.83      0.86      0.84       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.80      0.79      0.80      1532\n",
      "weighted avg       0.80      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  447  167\n",
      "1  130  788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74       614\n",
      "           1       0.81      0.87      0.84       918\n",
      "\n",
      "    accuracy                           0.80      1532\n",
      "   macro avg       0.80      0.79      0.79      1532\n",
      "weighted avg       0.80      0.80      0.80      1532\n",
      "\n",
      "     0    1\n",
      "0  431  183\n",
      "1  117  801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       614\n",
      "           1       0.84      0.86      0.85       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.81      0.80      0.80      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  459  155\n",
      "1  130  788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76       614\n",
      "           1       0.82      0.89      0.85       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.82      0.80      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  435  179\n",
      "1   99  819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       614\n",
      "           1       0.83      0.86      0.84       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.80      0.79      0.80      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  447  167\n",
      "1  128  790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76       614\n",
      "           1       0.82      0.89      0.86       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.82      0.80      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  441  173\n",
      "1  103  815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       614\n",
      "           1       0.83      0.87      0.85       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.81      0.80      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  451  163\n",
      "1  118  800\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.75       614\n",
      "           1       0.82      0.89      0.85       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.81      0.80      0.80      1532\n",
      "weighted avg       0.81      0.82      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  436  178\n",
      "1  105  813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       614\n",
      "           1       0.84      0.88      0.86       918\n",
      "\n",
      "    accuracy                           0.83      1532\n",
      "   macro avg       0.82      0.82      0.82      1532\n",
      "weighted avg       0.83      0.83      0.83      1532\n",
      "\n",
      "     0    1\n",
      "0  463  151\n",
      "1  112  806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75       614\n",
      "           1       0.81      0.89      0.85       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.81      0.79      0.80      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  429  185\n",
      "1  104  814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       614\n",
      "           1       0.83      0.88      0.86       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.82      0.81      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  450  164\n",
      "1  109  809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75       614\n",
      "           1       0.82      0.89      0.85       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.81      0.79      0.80      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  432  182\n",
      "1  105  813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       614\n",
      "           1       0.83      0.88      0.86       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.82      0.81      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  452  162\n",
      "1  110  808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75       614\n",
      "           1       0.82      0.88      0.85       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.81      0.80      0.80      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  438  176\n",
      "1  110  808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75       614\n",
      "           1       0.82      0.87      0.85       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.81      0.80      0.80      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  444  170\n",
      "1  121  797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76       614\n",
      "           1       0.82      0.89      0.85       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.82      0.80      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  439  175\n",
      "1  102  816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76       614\n",
      "           1       0.83      0.88      0.85       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.81      0.80      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  447  167\n",
      "1  111  807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       614\n",
      "           1       0.83      0.89      0.86       918\n",
      "\n",
      "    accuracy                           0.83      1532\n",
      "   macro avg       0.82      0.81      0.82      1532\n",
      "weighted avg       0.83      0.83      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  448  166\n",
      "1  100  818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75       614\n",
      "           1       0.82      0.88      0.85       918\n",
      "\n",
      "    accuracy                           0.81      1532\n",
      "   macro avg       0.81      0.80      0.80      1532\n",
      "weighted avg       0.81      0.81      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  437  177\n",
      "1  108  810\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76       614\n",
      "           1       0.82      0.90      0.86       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.82      0.80      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  434  180\n",
      "1   95  823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76       614\n",
      "           1       0.82      0.88      0.85       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.81      0.80      0.80      1532\n",
      "weighted avg       0.81      0.82      0.81      1532\n",
      "\n",
      "     0    1\n",
      "0  440  174\n",
      "1  109  809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       614\n",
      "           1       0.83      0.89      0.86       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.82      0.81      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  446  168\n",
      "1  105  813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       614\n",
      "           1       0.83      0.89      0.86       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.82      0.81      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  446  168\n",
      "1  104  814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76       614\n",
      "           1       0.82      0.90      0.86       918\n",
      "\n",
      "    accuracy                           0.82      1532\n",
      "   macro avg       0.82      0.80      0.81      1532\n",
      "weighted avg       0.82      0.82      0.82      1532\n",
      "\n",
      "     0    1\n",
      "0  435  179\n",
      "1   95  823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_matrix = np.arange(1, 50, 1)\n",
    "\n",
    "print(n_matrix.shape)\n",
    "\n",
    "# intialize matrix to keep track of tree number and scores\n",
    "forest_score_mat = np.zeros((n_matrix.shape[0],2))\n",
    "print(forest_score_mat.shape)\n",
    "\n",
    "k = 0\n",
    "for k,n in enumerate(n_matrix):\n",
    "    clf_this_forest = RandomForestClassifier(n_estimators=n)\n",
    "    eval_this_forest = evaluate_classifer(clf_this_forest, x_train, y_train, x_test, y_test)\n",
    "    \n",
    "    forest_score_mat[k][0] = n\n",
    "    forest_score_mat[k][1] = eval_this_forest['clf_score']\n",
    "# print(forest_score_mat)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(forest_score_mat[:,0],forest_score_mat[:,1])\n",
    "plt.xlabel('number trees')\n",
    "plt.ylabel('clf score')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
